---
layout: post
title: a post with code
date: 2015-07-15 15:09:00
description: an example of a blog post with some code
---


```python
#Data Preprocessing and basic statistics
import numpy as np
import pandas as pd

#Data Visualization
import matplotlib.pyplot as plt
import seaborn as sns

#To make visualizations look pretty for notebooks
%matplotlib inline

#For serious exploratory data analysis
import pandas_profiling

#Data Preprocessing
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import StandardScaler
```


```python
#Load the US department of labor dataset
from __future__ import division
try:
    df = pd.read_csv(r'C:\Users\adity\Downloads\Final_1.csv')
    print('The US depatment of labor dataset has {} samples with {} features each.'.format(*df.shape))
except:
    print('Dataset could not be loaded')
```

    The US depatment of labor dataset has 147230 samples with 14 features each.



```python
#A brief discription of the dataset
display(df.describe())
```


<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>case_status</th>
      <th>employer_num_employees</th>
      <th>case_solve_days</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>147230.000000</td>
      <td>1.472060e+05</td>
      <td>147229.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>0.606942</td>
      <td>2.569243e+04</td>
      <td>205.356146</td>
    </tr>
    <tr>
      <th>std</th>
      <td>0.739243</td>
      <td>6.912882e+05</td>
      <td>193.493659</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.000000</td>
      <td>0.000000e+00</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>0.000000</td>
      <td>8.900000e+01</td>
      <td>109.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>0.000000</td>
      <td>1.582000e+03</td>
      <td>160.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>1.000000</td>
      <td>2.250000e+04</td>
      <td>203.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>3.000000</td>
      <td>2.635506e+08</td>
      <td>3184.000000</td>
    </tr>
  </tbody>
</table>
</div>


The dataset consists of three numerical features of the 14 features present.
To get further insight from the data we are going to use 'pandas prifile' function to get summary statistics.


```python
#Summary statistics using pandas profile, the magic one line code
#df.profile_report(style={'full_width':True}, title='US Department of Labor', pool_size=4)
```

The pandas_profile function has some interesting things to portray:
- The dataset has a total of 0.9% missing values followed by 12.4% Duplicate rows.
- Of the 14 features,
    [case_solve_days, employer_num_employees] are numerical(2)
    [case_status, class_of_admission, foreign_worker_info_education, job_info_education, pw_level_9089, pw_source_name_9089, pw_unit_of_pay_9089, wage_offer_unit_of_pay_9089] are categorical(8)
    [job_info_alt_combo_ed_exp, job_info_alt_field, job_info_experience, job_info_job_req_normal] are Boolean(4)
- The employer_num_employees feature is highly skewed to the right.
- There is a strong positive linear correlation between case solved days and case status(Target Column) according to pearson's and spearman's correlation matrix.
- A mid negative correlation exists between number of employees and case status(Target column).  
- The phik and Cramers V correlational plots provides loose evidence that there exist stong correlation between job education and worker education and a mild correlation between job education and class of admission. Although, phik correlation needs further validation by pairwise evaluation of all the correlations, significance and outlier significance for further feature consideration. Likewise, a Chi-Square test needs to determine significance for Cramers V to determine strength of association.  

From the initial screening, the categorical and boolean variables need to be transformed in continous values


```python
#Replace blanks and null values in the dataframe with nan
df = df.replace([" ", "NULL"], np.nan)

#Remove null values from the dataset
df = df.dropna()
print()

#Drop duplicate rows from the dataset
df = df.drop_duplicates()

#Drop the columns having extreme values
df = df.drop(['pw_source_name_9089','pw_unit_of_pay_9089', 'wage_offer_unit_of_pay_9089'], axis=1)
```





```python
#Splitting the data in features and target label
case_status = df['case_status']
features_raw = df.drop('case_status', axis=1)
```


```python
#Skewed columns
df.skew()
print('\nSkewed data is {}'.format(df.skew()))
#Visualizing skewed data
df['employer_num_employees'].plot.hist(alpha=0.5, bins=20, grid=True, legend=None)
plt.xlabel('Feature Value')
plt.title('Histogram')
plt.show()
```


    Skewed data is case_status                 1.347406
    employer_num_employees    332.616928
    case_solve_days             4.924871
    dtype: float64



![png](output_8_1.png)



```python
#Carrying out log transformations
skewed = ['employer_num_employees']
features_raw[skewed] = df[skewed].apply(lambda x: np.log(x+1))
features_raw[skewed].plot.hist(alpha=0.5, bins=20, grid=True, legend=None)
plt.xlabel('Feature Value')
plt.title('Histogram')
plt.show()
```


![png](output_9_0.png)


Normalizing Numerical Features


```python
#Import sklearn.preprocessing.StandardScalar
from sklearn.preprocessing import MinMaxScaler

#Initialize to the scalar then apply it to the features
scalar = MinMaxScaler()
numerical = ['case_solve_days', 'employer_num_employees']
features_raw[numerical] = scalar.fit_transform(df[numerical])

#Show an example of the record
display(features_raw.head(n=1))
```


<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>class_of_admission</th>
      <th>employer_num_employees</th>
      <th>foreign_worker_info_education</th>
      <th>job_info_alt_combo_ed_exp</th>
      <th>job_info_alt_field</th>
      <th>job_info_education</th>
      <th>job_info_experience</th>
      <th>job_info_job_req_normal</th>
      <th>pw_level_9089</th>
      <th>case_solve_days</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>H-1B</td>
      <td>8.461373e-07</td>
      <td>Master's</td>
      <td>N</td>
      <td>N</td>
      <td>Master's</td>
      <td>Y</td>
      <td>N</td>
      <td>Level II</td>
      <td>0.030705</td>
    </tr>
  </tbody>
</table>
</div>


Data Preprocessing


```python
#One-hot encode the 'features_raw' data using pandas.get_dummies()
features = pd.get_dummies(features_raw)

#Print the number of features after one-hot encoding
encoded = list(features.columns)
print('{} total features after one hot encoding'.format(len(encoded)))
```

    74 total features after one hot encoding


Shuffle and Split the Data


```python
#To split the data in train and validation set
from sklearn.model_selection import train_test_split

#Split the features and case_status data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(features, case_status, test_size=0.2, random_state=0)

#Show the result of the split
print('Training set has {} samples.'.format(X_train.shape[0]))
print('Testing set has {} samples'.format(X_test.shape[0]))
```

    Training set has 91554 samples.
    Testing set has 22889 samples


Evaluating Model Performace

Supervised learning approach

Decision Tree, Support Vector Machines(SVM), Ensemble methods: AdaBoost  

Creating a Training and Predicting Pipeline


```python
#Import two metrics from sklearn - fbeta_score and accuracy_score
from sklearn.metrics import fbeta_score, accuracy_score
from time import time

def train_predict(learner, sample_size, X_train, y_train, X_test, y_test):
    '''
    Inputs:
        - learner: The learning algorithm to be trained and predicted on
        - sample_size: The size of samples (number) to be drawn from training set
        - X_train: Features training set
        - y_train: case_status training set
        - X_test: Features testing set
        - y_test: case_status testing set
    '''

    results = {}

    #Fit the learner to the training data using slicing with 'sample_size'
    start = time()
    learner = learner.fit(X_train[:sample_size],y_train[:sample_size])
    end = time()

    #Calculate training time
    results['train_time'] = end - start

    #Get the predictions on the test set followed by predictions on first 300 training samples
    start = time()
    predictions_test = learner.predict(X_test)
    predictions_train = learner.predict(X_train[:300])
    end = time()

    #Calculate the total prediction time
    results['pred_time'] = end - start

    #Compute accuracy on first 300 training samples
    results['acc_train'] = accuracy_score(y_train[:300], predictions_train)

    #Compute accuracy on the test set
    results['acc_test'] = accuracy_score(y_test, predictions_test)

    #Compute Fscore on first 300 training samples
    results['f_train'] = fbeta_score(y_train[:300], predictions_train, 0.5, average='micro')

    #Compute Fscore on testing set
    results['f_test'] = fbeta_score(y_test, predictions_test, 0.5, average='micro')

    #Success
    print("{} trained on {} samples".format(learner.__class__.__name__, sample_size))

    #Return the results
    return results
```


```python
import matplotlib.pyplot as pl
import matplotlib.patches as mpatches
from time import time
from sklearn.metrics import f1_score, accuracy_score

def evaluate(results):
    """
    Visualization code to display results of various learners.

    inputs:
      - learners: a list of supervised learners
      - stats: a list of dictionaries of the statistic results from 'train_predict()'
      - accuracy: The score for the naive predictor
      - f1: The score for the naive predictor
    """

    # Create figure
    fig, ax = pl.subplots(2, 4, figsize = (11,7))

    # Constants
    bar_width = 0.3
    colors = ['#A00000','#00A0A0','#00A000']

    # Super loop to plot four panels of data
    for k, learner in enumerate(results.keys()):
        for j, metric in enumerate(['train_time', 'acc_train', 'f_train', 'pred_time', 'acc_test', 'f_test']):
            for i in np.arange(3):

                # Creative plot code
                ax[j//3, j%3].bar(i+k*bar_width, results[learner][i][metric], width = bar_width, color = colors[k])
                ax[j//3, j%3].set_xticks([0.45, 1.45, 2.45])
                ax[j//3, j%3].set_xticklabels(["1%", "10%", "100%"])
                ax[j//3, j%3].set_xlabel("Training Set Size")
                ax[j//3, j%3].set_xlim((-0.1, 3.0))

    # Add unique y-labels
    ax[0, 0].set_ylabel("Time (in seconds)")
    ax[0, 1].set_ylabel("Accuracy Score")
    ax[0, 2].set_ylabel("F-score")
    ax[1, 0].set_ylabel("Time (in seconds)")
    ax[1, 1].set_ylabel("Accuracy Score")
    ax[1, 2].set_ylabel("F-score")

    # Add titles
    ax[0, 0].set_title("Model Training")
    ax[0, 1].set_title("Accuracy Score on Training Subset")
    ax[0, 2].set_title("F-score on Training Subset")
    ax[1, 0].set_title("Model Predicting")
    ax[1, 1].set_title("Accuracy Score on Testing Set")
    ax[1, 2].set_title("F-score on Testing Set")

    # Add horizontal lines for naive predictors
    #ax[0, 1].axhline(y = accuracy, xmin = -0.1, xmax = 3.0, linewidth = 1, color = 'k', linestyle = 'dashed')
    #ax[1, 1].axhline(y = accuracy, xmin = -0.1, xmax = 3.0, linewidth = 1, color = 'k', linestyle = 'dashed')
    #ax[0, 2].axhline(y = fscore, xmin = -0.1, xmax = 3.0, linewidth = 1, color = 'k', linestyle = 'dashed')
    #ax[1, 2].axhline(y = fscore, xmin = -0.1, xmax = 3.0, linewidth = 1, color = 'k', linestyle = 'dashed')

    # Set y-limits for score panels
    ax[0, 1].set_ylim((0, 1))
    ax[0, 2].set_ylim((0, 1))
    ax[1, 1].set_ylim((0, 1))
    ax[1, 2].set_ylim((0, 1))

    # Set additional plots invisibles
    ax[0, 3].set_visible(False)
    ax[1, 3].axis('off')

    # Create legend
    for i, learner in enumerate(results.keys()):
        pl.bar(0, 0, color=colors[i], label=learner)
    pl.legend()

    # Aesthetics
    pl.suptitle("Performance Metrics for Three Supervised Learning Models", fontsize = 16, y = 1.10)
    pl.tight_layout()
    pl.show()
```

Model Evaluation


```python
#Import supervised learning algorithms
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.ensemble import AdaBoostClassifier

#Initialize the model with random state to reproduce
clf_A = DecisionTreeClassifier(random_state=101)
clf_B = SVC(random_state=101)
clf_C = AdaBoostClassifier(random_state=101)

#Claculate the number of samples for 1%, 10% and 100% of the training data
samples_1 = int(round(len(X_train) / 100))
samples_10 = int(round(len(X_train) / 10))
samples_100 = len(X_train)

#Collect result on the learners
results = {}
for clf in [clf_A, clf_B, clf_C]:
    clf_name = clf.__class__.__name__
    results[clf_name] = {}
    for i, samples in enumerate([samples_1, samples_10, samples_100]):
        results[clf_name][i] = \
        train_predict(clf, samples, X_train, y_train, X_test, y_test)
```

    DecisionTreeClassifier trained on 916 samples
    DecisionTreeClassifier trained on 9155 samples
    DecisionTreeClassifier trained on 91554 samples


    c:\users\adity\appdata\local\programs\python\python37\lib\site-packages\sklearn\svm\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.
      "avoid this warning.", FutureWarning)


    SVC trained on 916 samples


    c:\users\adity\appdata\local\programs\python\python37\lib\site-packages\sklearn\svm\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.
      "avoid this warning.", FutureWarning)


    SVC trained on 9155 samples


    c:\users\adity\appdata\local\programs\python\python37\lib\site-packages\sklearn\svm\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.
      "avoid this warning.", FutureWarning)


    SVC trained on 91554 samples
    AdaBoostClassifier trained on 916 samples
    AdaBoostClassifier trained on 9155 samples
    AdaBoostClassifier trained on 91554 samples



```python
#Run metrics visualization for the three supervised learning models chosen
evaluate(results)
```


![png](output_24_0.png)



```python
#Printing out the values
for i in results.items():
    print(i[0])
    display(pd.DataFrame(i[1]).rename(columns={0:'1%', 1:'10%', 2:'100%'}))
```

    DecisionTreeClassifier



<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>1%</th>
      <th>10%</th>
      <th>100%</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>acc_test</th>
      <td>0.659007</td>
      <td>0.678929</td>
      <td>0.696492</td>
    </tr>
    <tr>
      <th>acc_train</th>
      <td>1.000000</td>
      <td>0.990000</td>
      <td>0.946667</td>
    </tr>
    <tr>
      <th>f_test</th>
      <td>0.659007</td>
      <td>0.678929</td>
      <td>0.696492</td>
    </tr>
    <tr>
      <th>f_train</th>
      <td>1.000000</td>
      <td>0.990000</td>
      <td>0.946667</td>
    </tr>
    <tr>
      <th>pred_time</th>
      <td>0.028949</td>
      <td>0.015956</td>
      <td>0.019946</td>
    </tr>
    <tr>
      <th>train_time</th>
      <td>0.009972</td>
      <td>0.073812</td>
      <td>1.028250</td>
    </tr>
  </tbody>
</table>
</div>


    SVC



<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>1%</th>
      <th>10%</th>
      <th>100%</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>acc_test</th>
      <td>0.512910</td>
      <td>0.512910</td>
      <td>0.512517</td>
    </tr>
    <tr>
      <th>acc_train</th>
      <td>0.456667</td>
      <td>0.456667</td>
      <td>0.450000</td>
    </tr>
    <tr>
      <th>f_test</th>
      <td>0.512910</td>
      <td>0.512910</td>
      <td>0.512517</td>
    </tr>
    <tr>
      <th>f_train</th>
      <td>0.456667</td>
      <td>0.456667</td>
      <td>0.450000</td>
    </tr>
    <tr>
      <th>pred_time</th>
      <td>1.607213</td>
      <td>16.138873</td>
      <td>160.303248</td>
    </tr>
    <tr>
      <th>train_time</th>
      <td>0.085803</td>
      <td>8.453359</td>
      <td>1040.355758</td>
    </tr>
  </tbody>
</table>
</div>


    AdaBoostClassifier



<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>1%</th>
      <th>10%</th>
      <th>100%</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>acc_test</th>
      <td>0.618419</td>
      <td>0.741666</td>
      <td>0.766656</td>
    </tr>
    <tr>
      <th>acc_train</th>
      <td>0.666667</td>
      <td>0.726667</td>
      <td>0.726667</td>
    </tr>
    <tr>
      <th>f_test</th>
      <td>0.618419</td>
      <td>0.741666</td>
      <td>0.766656</td>
    </tr>
    <tr>
      <th>f_train</th>
      <td>0.666667</td>
      <td>0.726667</td>
      <td>0.726667</td>
    </tr>
    <tr>
      <th>pred_time</th>
      <td>0.434796</td>
      <td>0.385969</td>
      <td>0.392952</td>
    </tr>
    <tr>
      <th>train_time</th>
      <td>0.068992</td>
      <td>0.514631</td>
      <td>5.504270</td>
    </tr>
  </tbody>
</table>
</div>



```python
#Visualize the confusion matrix for each classifier
from sklearn.metrics import confusion_matrix

for i,model in enumerate([clf_A, clf_B, clf_C]):
    cm = confusion_matrix(y_test, model.predict(X_test))
    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] # normalize the data

    # view with a heatmap
    plt.figure(i)
    sns.heatmap(cm, annot=True, annot_kws={"size":10},
            cmap='Blues', square=True, fmt='.3f')
    plt.ylabel('True label')
    plt.xlabel('Predicted label')
    plt.title('Confusion matrix for:\n{}'.format(model.__class__.__name__));
```


![png](output_26_0.png)



![png](output_26_1.png)



![png](output_26_2.png)



```python
# TODO: Import 'GridSearchCV', 'make_scorer', and any other necessary libraries
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import make_scorer

# TODO: Initialize the classifier
clf = AdaBoostClassifier(base_estimator=DecisionTreeClassifier())

# TODO: Create the parameters list you wish to tune
parameters = {'n_estimators':[50, 120],
              'learning_rate':[0.1, 0.5, 1.],
              'base_estimator__min_samples_split' : np.arange(2, 8, 2),
              'base_estimator__max_depth' : np.arange(1, 4, 1)
             }

# TODO: Make an fbeta_score scoring object
scorer = make_scorer(fbeta_score,beta=0.5, average='micro')

# TODO: Perform grid search on the classifier using 'scorer' as the scoring method
grid_obj = GridSearchCV(clf, parameters,scorer)

# TODO: Fit the grid search object to the training data and find the optimal parameters
grid_fit = grid_obj.fit(X_train,y_train)

# Get the estimator
best_clf = grid_fit.best_estimator_

# Make predictions using the unoptimized and model
predictions = (clf.fit(X_train, y_train)).predict(X_test)
best_predictions = best_clf.predict(X_test)

# Report the before-and-afterscores
print("Unoptimized model\n------")
print("Accuracy score on testing data: {:.4f}".format(accuracy_score(y_test, predictions)))
print("F-score on testing data: {:.4f}".format(fbeta_score(y_test, predictions, beta = 0.5, average='micro')))
print("\nOptimized Model\n------")
print("Final accuracy score on the testing data: {:.4f}".format(accuracy_score(y_test, best_predictions)))
print("Final F-score on the testing data: {:.4f}".format(fbeta_score(y_test, best_predictions, beta = 0.5, average='micro')))
print(best_clf)

```

    c:\users\adity\appdata\local\programs\python\python37\lib\site-packages\sklearn\model_selection\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.
      warnings.warn(CV_WARNING, FutureWarning)


    Unoptimized model
    ------
    Accuracy score on testing data: 0.7331
    F-score on testing data: 0.7331

    Optimized Model
    ------
    Final accuracy score on the testing data: 0.7725
    Final F-score on the testing data: 0.7725
    AdaBoostClassifier(algorithm='SAMME.R',
                       base_estimator=DecisionTreeClassifier(class_weight=None,
                                                             criterion='gini',
                                                             max_depth=3,
                                                             max_features=None,
                                                             max_leaf_nodes=None,
                                                             min_impurity_decrease=0.0,
                                                             min_impurity_split=None,
                                                             min_samples_leaf=1,
                                                             min_samples_split=2,
                                                             min_weight_fraction_leaf=0.0,
                                                             presort=False,
                                                             random_state=None,
                                                             splitter='best'),
                       learning_rate=0.1, n_estimators=50, random_state=None)


Extracting feature importance


```python
def feature_plot(importances, X_train, y_train):

    # Display the five most important features
    indices = np.argsort(importances)[::-1]
    columns = X_train.columns.values[indices[:5]]
    values = importances[indices][:5]

    # Creat the plot
    fig = pl.figure(figsize = (9,5))
    pl.title("Normalized Weights for First Five Most Predictive Features", fontsize = 16)
    pl.bar(np.arange(5), values, width = 0.6, align="center", color = '#00A000', \
          label = "Feature Weight")
    pl.bar(np.arange(5) - 0.3, np.cumsum(values), width = 0.2, align = "center", color = '#00A0A0', \
          label = "Cumulative Feature Weight")
    pl.xticks(np.arange(5), columns)
    pl.xlim((-0.5, 4.5))
    pl.ylabel("Weight", fontsize = 12)
    pl.xlabel("Feature", fontsize = 12)

    pl.legend(loc = 'upper center')
    pl.tight_layout()
    pl.show()
```


```python
#Train the supervised model on the training set
model = AdaBoostClassifier().fit(X_train, y_train)

#Extract the feature importnace
importances = model.feature_importances_

#Plot
feature_plot(importances, X_train, y_train)
```


![png](output_30_0.png)



```python
#Import functionality for a cloning model
from sklearn.base import clone

#Reduce the feature space
X_train_reduced = X_train[X_train.columns.values[(np.argsort(importances)[::-1])[:5]]]
X_test_reduced = X_test[X_test.columns.values[(np.argsort(importances)[::-1])[:5]]]

#Train on the best model found from grid search earlier
clf = (clone(best_clf)).fit(X_train_reduced, y_train)

#Make new prediction
reduced_predictions = clf.predict(X_test_reduced)

# Report scores from the final model using both versions of data
print("Final Model trained on full data\n------")
print("Accuracy on testing data: {:.4f}".format(accuracy_score(y_test, best_predictions)))
print("F-score on testing data: {:.4f}".format(fbeta_score(y_test, best_predictions, beta = 0.5, average='micro')))
print("\nFinal Model trained on reduced data\n------")
print("Accuracy on testing data: {:.4f}".format(accuracy_score(y_test, reduced_predictions)))
print("F-score on testing data: {:.4f}".format(fbeta_score(y_test, reduced_predictions, beta = 0.5, average='micro')))
```

    Final Model trained on full data
    ------
    Accuracy on testing data: 0.7725
    F-score on testing data: 0.7725

    Final Model trained on reduced data
    ------
    Accuracy on testing data: 0.7736
    F-score on testing data: 0.7736



```python

```

<!--
This theme implements a built-in Jekyll feature, the use of Pygments, for sytanx highlighting. It supports more than 100 languages. This example is in C++. All you have to do is wrap your code in a liquid tag:
{% raw  %}
{% highlight c++ %}  <br/> code code code <br/> {% endhighlight %}{% endraw %}

Produces something like this:

{% highlight c++ %}

int main(int argc, char const *argv[])
{
	string myString;

	cout << "input a string: ";
	getline(cin, myString);
	int length = myString.length();

	char charArray = new char * [length];

	charArray = myString;
	for(int i = 0; i < length; ++i){
		cout << charArray[i] << " ";
	}

	return 0;
}

{% endhighlight %}
-->
